{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8.Train a Keras Neural Network With ImageNet Synsets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehotosh/Deep-Learning/blob/master/8_Train_a_Keras_Neural_Network_With_ImageNet_Synsets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oAPuEZ0AovKQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#1 \"How to get Images from ImageNet with Python in Google Colaboratory\"\n",
        "\n",
        "The code for the actual post \"Train a Keras Neural Network With ImageNet Synsets in Google Colaboratory\" starts below on step 2 after getting the Images."
      ]
    },
    {
      "metadata": {
        "id": "2ihabI0hUjuh",
        "colab_type": "code",
        "outputId": "01ddc3c7-9218-40d3-ffec-715be39b26d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#code part 1\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mI4Yn3Eqr1Pr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Ship Images\n",
        "ships_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\")\n",
        "print(ships_page.content)\n",
        "\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "ships_soup = BeautifulSoup(ships_page.content, 'html.parser') #puts the content of the website into the soup variable, each url on a different line\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9RT0gP_5nlWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Bike Images\n",
        "bikes_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02834778\")\n",
        "print(bikes_page.content)\n",
        "\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "bikes_soup = BeautifulSoup(bikes_page.content, 'html.parser') #puts the content of the website into the soup variable, each url on a different line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_2AMNyam_nD",
        "colab_type": "code",
        "outputId": "e434d9ac-f55f-4ae0-905e-c5127fcbe8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#code part 2\n",
        "str_soup=str(ships_soup) #convert soup to string so it can be split\n",
        "print(type(str_soup))\n",
        "\n",
        "split_urls=str_soup.split('\\r\\n') #split so each url is a different position on a list\n",
        "print(len(split_urls)) #print the length of the list so you know how many urls you have"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "1262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vVPl9aGooPC9",
        "colab_type": "code",
        "outputId": "9f9c405e-89eb-4162-d809-75eb965563eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#code part 2.2\n",
        "bikes_str_soup=str(bikes_soup) #convert soup to string so it can be split\n",
        "print(type(bikes_str_soup))\n",
        "\n",
        "bikes_split_urls=bikes_str_soup.split('\\r\\n') #split so each url is a different position on a list\n",
        "print(len(bikes_split_urls))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "1345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DXzwLv_ks-uT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b7e2442-baa4-41fa-baab-2f3cbef33fad"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mh1OY8SUxgu0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#code part 3\n",
        "\n",
        "## Create Train Folder for ships and bikes\n",
        "!mkdir /content/train #create the Train folder\n",
        "!mkdir /content/train/ships #create the ships folder\n",
        "!mkdir /content/train/bikes #create the bikes folder\n",
        "\n",
        "## Create Validation Folder for ships and bikes\n",
        "!mkdir /content/validation\n",
        "!mkdir /content/validation/ships #create the ships folder\n",
        "!mkdir /content/validation/bikes #create the bikes folder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3emILG9etkvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1128fdbe-875f-4d97-d360-1fadff212841"
      },
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  train  validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IfvdvHYElJdS",
        "colab_type": "code",
        "outputId": "27ee218d-581d-43ba-b391-5f5298b26606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1258
        }
      },
      "cell_type": "code",
      "source": [
        "#code part 4\n",
        "img_rows, img_cols = 32, 32 #number of rows and columns to convert the images to\n",
        "input_shape = (img_rows, img_cols, 3) #format to store the images (rows, columns,channels) called channels last\n",
        "\n",
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\t# return the image\n",
        "\treturn image\n",
        "\n",
        "n_of_training_images=100  # the number of training images to use\n",
        "\n",
        "##########################\n",
        "# For Ships:\n",
        "##########################\n",
        "for progress in range(n_of_training_images): # store all the images in a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/ships/img'+str(progress)+'.jpg' #create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "##########################\n",
        "# For bikes:\n",
        "##########################\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "####################        \n",
        "#Validation data:\n",
        "####################\n",
        "\n",
        "##########################\n",
        "# For Ships:\n",
        "##########################\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/ships/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "##########################\n",
        "# For bikes:\n",
        "##########################\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "print(\"\\nTRAIN:\\n\")          \n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/train/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/train/bikes #list the files inside bikes\n",
        "print(\"\\nVALIDATION:\\n\")\n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/validation/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/validation/bikes #list the files inside bikes   "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "0\n",
            "20\n",
            "40\n",
            "0\n",
            "20\n",
            "40\n",
            "\n",
            "TRAIN:\n",
            "\n",
            "\n",
            "list the files inside ships directory:\n",
            "\n",
            "img0.jpg   img23.jpg  img35.jpg  img4.jpg   img62.jpg  img76.jpg  img92.jpg\n",
            "img10.jpg  img24.jpg  img37.jpg  img50.jpg  img63.jpg  img77.jpg  img93.jpg\n",
            "img11.jpg  img25.jpg  img39.jpg  img51.jpg  img64.jpg  img78.jpg  img94.jpg\n",
            "img12.jpg  img26.jpg  img3.jpg\t img52.jpg  img65.jpg  img7.jpg   img95.jpg\n",
            "img14.jpg  img27.jpg  img40.jpg  img53.jpg  img66.jpg  img80.jpg  img96.jpg\n",
            "img15.jpg  img28.jpg  img42.jpg  img54.jpg  img67.jpg  img83.jpg  img97.jpg\n",
            "img16.jpg  img29.jpg  img43.jpg  img55.jpg  img68.jpg  img84.jpg  img98.jpg\n",
            "img17.jpg  img2.jpg   img44.jpg  img56.jpg  img69.jpg  img85.jpg  img99.jpg\n",
            "img18.jpg  img30.jpg  img45.jpg  img57.jpg  img6.jpg   img86.jpg  img9.jpg\n",
            "img19.jpg  img31.jpg  img46.jpg  img58.jpg  img72.jpg  img87.jpg\n",
            "img1.jpg   img32.jpg  img47.jpg  img59.jpg  img73.jpg  img89.jpg\n",
            "img20.jpg  img33.jpg  img48.jpg  img5.jpg   img74.jpg  img8.jpg\n",
            "img21.jpg  img34.jpg  img49.jpg  img60.jpg  img75.jpg  img91.jpg\n",
            "\n",
            "list the files inside bikes directory:\n",
            "\n",
            "img0.jpg   img27.jpg  img40.jpg  img56.jpg  img69.jpg  img80.jpg  img93.jpg\n",
            "img10.jpg  img29.jpg  img41.jpg  img58.jpg  img6.jpg   img81.jpg  img95.jpg\n",
            "img11.jpg  img30.jpg  img43.jpg  img59.jpg  img70.jpg  img82.jpg  img96.jpg\n",
            "img13.jpg  img31.jpg  img44.jpg  img5.jpg   img71.jpg  img83.jpg  img97.jpg\n",
            "img14.jpg  img32.jpg  img45.jpg  img60.jpg  img72.jpg  img84.jpg  img98.jpg\n",
            "img15.jpg  img33.jpg  img47.jpg  img62.jpg  img73.jpg  img85.jpg  img99.jpg\n",
            "img17.jpg  img34.jpg  img48.jpg  img63.jpg  img74.jpg  img86.jpg  img9.jpg\n",
            "img19.jpg  img35.jpg  img4.jpg\t img64.jpg  img75.jpg  img87.jpg\n",
            "img21.jpg  img36.jpg  img50.jpg  img65.jpg  img76.jpg  img88.jpg\n",
            "img22.jpg  img37.jpg  img51.jpg  img66.jpg  img77.jpg  img89.jpg\n",
            "img25.jpg  img38.jpg  img53.jpg  img67.jpg  img78.jpg  img90.jpg\n",
            "img26.jpg  img3.jpg   img54.jpg  img68.jpg  img79.jpg  img92.jpg\n",
            "\n",
            "VALIDATION:\n",
            "\n",
            "\n",
            "list the files inside ships directory:\n",
            "\n",
            "img0.jpg   img17.jpg  img26.jpg  img32.jpg  img3.jpg   img46.jpg  img8.jpg\n",
            "img10.jpg  img18.jpg  img27.jpg  img33.jpg  img40.jpg  img47.jpg\n",
            "img11.jpg  img1.jpg   img28.jpg  img35.jpg  img41.jpg  img48.jpg\n",
            "img12.jpg  img20.jpg  img29.jpg  img36.jpg  img42.jpg  img49.jpg\n",
            "img13.jpg  img22.jpg  img2.jpg\t img37.jpg  img43.jpg  img5.jpg\n",
            "img15.jpg  img23.jpg  img30.jpg  img38.jpg  img44.jpg  img6.jpg\n",
            "img16.jpg  img25.jpg  img31.jpg  img39.jpg  img45.jpg  img7.jpg\n",
            "\n",
            "list the files inside bikes directory:\n",
            "\n",
            "img0.jpg   img17.jpg  img23.jpg  img30.jpg  img38.jpg  img44.jpg  img5.jpg\n",
            "img10.jpg  img18.jpg  img24.jpg  img32.jpg  img39.jpg  img45.jpg  img6.jpg\n",
            "img12.jpg  img19.jpg  img26.jpg  img33.jpg  img3.jpg   img46.jpg  img7.jpg\n",
            "img13.jpg  img1.jpg   img27.jpg  img34.jpg  img40.jpg  img47.jpg  img8.jpg\n",
            "img14.jpg  img20.jpg  img28.jpg  img35.jpg  img41.jpg  img48.jpg\n",
            "img15.jpg  img21.jpg  img29.jpg  img36.jpg  img42.jpg  img49.jpg\n",
            "img16.jpg  img22.jpg  img2.jpg\t img37.jpg  img43.jpg  img4.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K1fFMYtxcMtr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#2 Train a Keras Neural Network With ImageNet Synsets in Google Colaboratory"
      ]
    },
    {
      "metadata": {
        "id": "WST6UGs-DA9I",
        "colab_type": "code",
        "outputId": "ab60762b-6cbd-49a3-cecf-4edae80ed862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#code part 5\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "train_datagen  = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "    \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train/',\n",
        "        target_size=(img_rows, img_cols),#The target_size is the size of your input images,every image will be resized to this size\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/validation/',\n",
        "        target_size=(img_rows, img_cols),#The target_size is the size of your input images,every image will be resized to this size\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 166 images belonging to 2 classes.\n",
            "Found 89 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hTyuOenOywql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential,Model,Input\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zty0XDIRyUIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "859aad54-367c-48a4-bb39-2ec90b8ef424"
      },
      "cell_type": "code",
      "source": [
        "## Model Architecture\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) \n",
        "model2.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "#--------------------------\n",
        "model2.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) \n",
        "model2.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "#--------------------------\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(16, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model2.summary() #prints the summary of the model that was created"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 4)         112       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 8)         296       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 4)         292       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 10, 10, 8)         296       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 5, 8)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                3216      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 4,246\n",
            "Trainable params: 4,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4kl15AmnyOTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oOP6zcdZyO6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Didnt run because it was taking too much time.Used the saved model and weights instead.\n",
        "model2.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000,\n",
        "        epochs=65, validation_data=validation_generator\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXws0SkxZAwj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Save the trained Model Using JSON and upload to google drive"
      ]
    },
    {
      "metadata": {
        "id": "3QRgssuoZAPa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model2.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model2.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpKtBIohZpOS",
        "colab_type": "code",
        "outputId": "d75b40f3-d9c3-422e-fac2-2d6e53ad5fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#check the names of the files and use them to upload to drive\n",
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  train  validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R-LkaJ_vBL0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb2dd0aa-55f0-430e-9445-d0ba360ae090"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 2.5MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 2.4MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 2.8MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.1MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 2.5MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 2.7MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.0MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.0MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 7.5MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 7.5MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 7.5MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 7.6MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 7.8MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 45.4MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 42.3MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 8.7MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 8.6MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 8.7MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 8.7MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 8.7MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 8.5MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 8.6MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 8.6MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 8.6MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 8.8MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 48.1MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 49.5MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 8.2MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 7.9MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 7.9MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 8.1MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 8.1MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 8.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 8.1MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 8.1MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 8.1MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 8.1MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 48.8MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 56.1MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 56.5MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 57.5MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 57.3MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 57.5MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 57.3MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 53.6MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 52.0MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 52.3MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 52.9MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 56.2MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 56.5MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 54.8MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 53.1MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 53.2MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 52.2MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 55.6MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 56.0MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 56.8MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 56.2MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 56.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 40.6MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 40.8MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 13.8MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 13.7MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 13.7MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 13.8MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 13.8MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 13.7MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 13.7MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 13.7MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 15.1MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 15.2MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 58.0MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 60.2MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 60.2MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 59.6MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 59.3MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 59.8MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 59.7MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 54.0MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 53.2MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 52.1MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 51.7MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 51.4MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 51.9MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 52.6MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 52.4MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 52.9MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 52.5MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 58.3MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 58.4MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 59.8MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 20.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kOPkr-6II_nB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use if you want to upload a file"
      ]
    },
    {
      "metadata": {
        "id": "dbMNnBaqF0n1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# file: string (name of existing file)\n",
        "# title: string (name which you want to give to the file being uploaded to Drive)\n",
        "# returns the file_id of the uploaded file on Drive\n",
        "def upload_file_to_drive(file, title):\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  export = drive.CreateFile({'title':title})  \n",
        "  export.SetContentFile(file)\n",
        "  export.Upload()\n",
        "\n",
        "  return export['id']  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2SGncRUat8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_id = upload_file_to_drive('model.json', 'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OtNFtsQFJFBq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use if you want to download a file"
      ]
    },
    {
      "metadata": {
        "id": "903IVRanHA4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# file_id: string (id of the file you want to download)\n",
        "# title: string (name which you want to give to the file being downloaded)\n",
        "def download_file_from_drive(file_id, title):\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  \n",
        "  download = drive.CreateFile({'id': file_id})\n",
        "  download.GetContentFile(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8kK9eIame8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Right-click on the file in Google Drive and click \"Get Shareable Link\".The URL will be copied to clipboard.take the ID from the link\n",
        "model=download_file_from_drive('11GZS4tJjVmkicLik4wFED6Gr-ChnieUb', 'model.h5') # id can be any number\n",
        "weights=download_file_from_drive('19fV4JoyZHjt6FtTRRr-e4At_wEq7Akbj', 'model.json')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HvbKlVeV2D-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ad73d1c-cf0b-4157-f32b-17d4dcc30c5e"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  model.h5  model.json\tsample_data  train  validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WEYZ_M7R1JeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "5d3d074c-8313-4660-98b5-42c07cc0d2b0"
      },
      "cell_type": "code",
      "source": [
        "!cat adc.json"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"client_id\": \"32555940559.apps.googleusercontent.com\",\n",
            "  \"client_secret\": \"ZmssLNjJy2998hD4CTg2ejr2\",\n",
            "  \"id_token\": {\n",
            "    \"at_hash\": \"n4raku8I6KjJA8odTbpSUw\",\n",
            "    \"aud\": \"32555940559.apps.googleusercontent.com\",\n",
            "    \"azp\": \"32555940559.apps.googleusercontent.com\",\n",
            "    \"email\": \"snehotosh.banerjee@gmail.com\",\n",
            "    \"email_verified\": true,\n",
            "    \"exp\": 1552902608,\n",
            "    \"iat\": 1552899008,\n",
            "    \"iss\": \"https://accounts.google.com\",\n",
            "    \"sub\": \"118151407154853057149\"\n",
            "  },\n",
            "  \"refresh_token\": \"1/QE0WNLyBo7caQ2o8bICwVVfs4choOekcI_C6AMYD4uI\",\n",
            "  \"revoke_uri\": \"https://accounts.google.com/o/oauth2/revoke\",\n",
            "  \"scopes\": [\n",
            "    \"https://www.googleapis.com/auth/drive\",\n",
            "    \"https://www.googleapis.com/auth/appengine.admin\",\n",
            "    \"https://www.googleapis.com/auth/accounts.reauth\",\n",
            "    \"https://www.googleapis.com/auth/cloud-platform\",\n",
            "    \"https://www.googleapis.com/auth/compute\",\n",
            "    \"https://www.googleapis.com/auth/userinfo.email\"\n",
            "  ],\n",
            "  \"token_response\": {\n",
            "    \"access_token\": \"ya29.GlvQBmn4maf4Ri13RuyK_GMvIRg559IJaKAPiukzj4ttvusldg4_tQvr6gOMEos27GQMabOdd-_NlTSKYaZgqCL04PvLDxK1wKN1b25KUIsA5-cwAukF4fugbuSC\",\n",
            "    \"expires_in\": 3600,\n",
            "    \"id_token\": \"eyJhbGciOiJSUzI1NiIsImtpZCI6IjVmZTJkNTQxYTQyODJiN2FlMzYyOGZhMDc0ZGQ4YmVhNmRhNWIxOWIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIzMjU1NTk0MDU1OS5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsImF1ZCI6IjMyNTU1OTQwNTU5LmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwic3ViIjoiMTE4MTUxNDA3MTU0ODUzMDU3MTQ5IiwiZW1haWwiOiJzbmVob3Rvc2guYmFuZXJqZWVAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF0X2hhc2giOiJuNHJha3U4STZLakpBOG9kVGJwU1V3IiwiaWF0IjoxNTUyODk5MDA4LCJleHAiOjE1NTI5MDI2MDh9.zgOLyrs5LYIfxN0aP8qeNYqFWyYQhXV5Wur25adWjguft4dN1JWWDS-N0zbRn3eF0nljDh2yfVcyeNYgTnoj3Yq_zXhYqvw2be4WrKTHRfx2XOsFJ-aoDwQz3GFcBJhaReSQCNpfHc_6aRt4tL172XZb1IsrfuCMTnV6keCPn7BaMhWxWqrGEsv_bOVRmYllteCrPfXDxf2lv4Pa5lVCtV1KS25GJFCIgX1GYuM0-MxawxfpNUtxYQVh4hZE_HSS_eoJk8b20xBsYUu5wtUnVcbCW-FZ0AuRUB_NDijLVYCuXxKSQ7HuUWc7WBSq_luR_nfzASBkcRbHNV9kCPGKcQ\",\n",
            "    \"refresh_token\": \"1/QE0WNLyBo7caQ2o8bICwVVfs4choOekcI_C6AMYD4uI\",\n",
            "    \"scope\": \"https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/compute https://www.googleapis.com/auth/drive openid https://www.googleapis.com/auth/appengine.admin https://www.googleapis.com/auth/userinfo.email https://www.googleapis.com/auth/accounts.reauth\",\n",
            "    \"token_type\": \"Bearer\"\n",
            "  },\n",
            "  \"token_uri\": \"https://www.googleapis.com/oauth2/v4/token\",\n",
            "  \"type\": \"authorized_user\",\n",
            "  \"user_agent\": \"google-cloud-sdk\"\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ysc5r7G9ngp0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#compile pretrained JSON model"
      ]
    },
    {
      "metadata": {
        "id": "iCMvyjuinmeV",
        "colab_type": "code",
        "outputId": "981af614-c224-4e0c-9a36-a23b2c759e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "#score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "#print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DB5rCAOZbq12",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Test the Trained Model"
      ]
    },
    {
      "metadata": {
        "id": "bw_2KLMHSOED",
        "colab_type": "code",
        "outputId": "6a73044a-4e14-4d72-a110-8780210f0aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#code part 6\n",
        "#create directory to store a .jpg image to recognize\n",
        "!mkdir /content/recognize\n",
        "\n",
        "def url_to_image(url):\n",
        "  # download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  I = image\n",
        "  if (len(I.shape))==3: #check if the image has width, length and channels, as I found some withouth channel\n",
        "    save_path = '/content/recognize/img1.jpg'\n",
        "    cv2.imwrite(save_path,I)\n",
        "\t# return the image\n",
        "  return image\n",
        "\n",
        "actual_image = url_to_image('https://www.jsea.or.jp/wp/wp-content/themes/nihon_senpaku/img/top/img02.jpg')# enter the url of the .jpg image\n",
        "\n",
        "img_path = '/content/recognize/img1.jpg'\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "#x = preprocess_input(x)\n",
        "#preds = model2.predict(x)\n",
        "preds = loaded_model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "\n",
        "print('Probability that the image is a Bicycle:', preds[0,0])\n",
        "print('Probability that the image is a Ship:', preds[0,1])\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability that the image is a Bicycle: 0.0\n",
            "Probability that the image is a Ship: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dViPfWuFTYbq",
        "colab_type": "code",
        "outputId": "c525b4b3-8ac3-4c3a-bdfa-c29ad695a153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#check if the image was stored on the directory\n",
        "!ls /content/recognize\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img1.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YzrqDfe9BbG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}